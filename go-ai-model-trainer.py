#!/usr/bin/env python3
"""
Go AI Model Trainer
Custom AI model training specifically for Go development
"""

import os
import json
import requests
import time
import re
from typing import List, Dict, Optional
from dataclasses import dataclass
from pathlib import Path
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TrainingConfig:
    """Configuration for model training"""
    base_model: str = "microsoft/DialoGPT-medium"
    output_dir: str = "./go-ai-model"
    max_length: int = 512
    batch_size: int = 4
    num_epochs: int = 3
    learning_rate: float = 5e-5
    warmup_steps: int = 500
    weight_decay: float = 0.01
    save_steps: int = 1000
    eval_steps: int = 1000
    logging_steps: int = 100

class GitHubGoScraper:
    """Scraper for GitHub Go repositories"""
    
    def __init__(self, token: str):
        self.token = token
        self.headers = {
            'Authorization': f'token {token}',
            'Accept': 'application/vnd.github.v3+json'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
    
    def get_top_go_repos(self, limit: int = 1000) -> List[Dict]:
        """Get top Go repositories by stars"""
        logger.info(f"Fetching top {limit} Go repositories...")
        repos = []
        page = 1
        
        while len(repos) < limit:
            url = "https://api.github.com/search/repositories"
            params = {
                'q': 'language:go',
                'sort': 'stars',
                'order': 'desc',
                'per_page': 100,
                'page': page
            }
            
            try:
                response = self.session.get(url, params=params)
                response.raise_for_status()
                
                data = response.json()
                repos.extend(data['items'])
                page += 1
                
                # Rate limiting
                time.sleep(1)
                
                logger.info(f"Fetched {len(repos)} repositories so far...")
                
            except requests.RequestException as e:
                logger.error(f"Error fetching repositories: {e}")
                break
        
        return repos[:limit]
    
    def get_repo_files(self, repo: str, max_files: int = 100) -> List[Dict]:
        """Get Go files from a repository"""
        logger.info(f"Fetching files from {repo}...")
        
        try:
            # Get repository tree
            url = f"https://api.github.com/repos/{repo}/git/trees/main"
            params = {'recursive': '1'}
            
            response = self.session.get(url, params=params)
            response.raise_for_status()
            
            tree = response.json()
            go_files = []
            
            for item in tree.get('tree', []):
                if (item['type'] == 'blob' and 
                    item['path'].endswith('.go') and 
                    len(go_files) < max_files):
                    go_files.append(item)
            
            return go_files
            
        except requests.RequestException as e:
            logger.error(f"Error fetching files from {repo}: {e}")
            return []
    
    def download_file_content(self, repo: str, path: str) -> Optional[str]:
        """Download file content from GitHub"""
        try:
            url = f"https://api.github.com/repos/{repo}/contents/{path}"
            response = self.session.get(url)
            response.raise_for_status()
            
            data = response.json()
            import base64
            content = base64.b64decode(data['content']).decode('utf-8')
            
            # Rate limiting
            time.sleep(0.1)
            
            return content
            
        except requests.RequestException as e:
            logger.error(f"Error downloading {path} from {repo}: {e}")
            return None

class GoDataProcessor:
    """Process and clean Go code data"""
    
    def __init__(self):
        self.go_keywords = {
            'package', 'import', 'func', 'var', 'const', 'type', 'interface',
            'struct', 'chan', 'go', 'select', 'defer', 'panic', 'recover',
            'if', 'else', 'for', 'range', 'switch', 'case', 'default',
            'return', 'break', 'continue', 'fallthrough', 'goto'
        }
    
    def clean_go_code(self, code: str) -> str:
        """Clean and normalize Go code"""
        # Remove comments
        code = re.sub(r'//.*$', '', code, flags=re.MULTILINE)
        code = re.sub(r'/\*.*?\*/', '', code, flags=re.DOTALL)
        
        # Remove extra whitespace
        code = re.sub(r'\n\s*\n', '\n', code)
        code = code.strip()
        
        return code
    
    def extract_go_patterns(self, code: str) -> List[str]:
        """Extract common Go patterns"""
        patterns = []
        
        # Function definitions
        func_pattern = r'func\s+\w+\s*\([^)]*\)\s*(?:\w+\s+)?\{[^}]*\}'
        patterns.extend(re.findall(func_pattern, code, re.DOTALL))
        
        # Interface definitions
        interface_pattern = r'type\s+\w+\s+interface\s*\{[^}]*\}'
        patterns.extend(re.findall(interface_pattern, code, re.DOTALL))
        
        # Struct definitions
        struct_pattern = r'type\s+\w+\s+struct\s*\{[^}]*\}'
        patterns.extend(re.findall(struct_pattern, code, re.DOTALL))
        
        return patterns
    
    def create_training_pairs(self, code: str, context: str = "") -> List[Dict]:
        """Create training pairs for fine-tuning"""
        pairs = []
        
        if not code.strip():
            return pairs
        
        # Code explanation pairs
        pairs.append({
            "prompt": f"Explain this Go code:\n\n{code[:500]}",
            "completion": f"This Go code {context}. Here's what it does:\n\n[Detailed explanation of the code structure, functionality, and Go-specific patterns used]"
        })
        
        # Code generation pairs
        if context:
            pairs.append({
                "prompt": f"Write Go code for: {context}",
                "completion": code[:500]
            })
        
        # Debugging pairs
        pairs.append({
            "prompt": f"Debug this Go code:\n\n{code[:500]}",
            "completion": f"Here are potential issues and improvements:\n\n[Analysis of code quality, potential bugs, and Go best practices]"
        })
        
        # Best practices pairs
        pairs.append({
            "prompt": f"Improve this Go code:\n\n{code[:500]}",
            "completion": f"Here's an improved version following Go best practices:\n\n[Refactored code with explanations of improvements]"
        })
        
        return pairs

class GoDocsScraper:
    """Scraper for Go documentation and examples"""
    
    def __init__(self):
        self.base_url = "https://golang.org"
        self.session = requests.Session()
    
    def scrape_documentation(self) -> Dict[str, str]:
        """Scrape Go documentation"""
        logger.info("Scraping Go documentation...")
        docs = {}
        
        pages = [
            "/doc/",
            "/doc/tutorial/",
            "/doc/effective_go.html",
            "/doc/code.html",
            "/doc/faq",
            "/doc/debugging_with_gdb.html",
            "/doc/diagnostics.html"
        ]
        
        for page in pages:
            try:
                url = f"{self.base_url}{page}"
                response = self.session.get(url)
                response.raise_for_status()
                
                # Extract text content (simplified)
                content = response.text
                docs[page] = content
                
                time.sleep(0.5)  # Rate limiting
                
            except requests.RequestException as e:
                logger.error(f"Error scraping {page}: {e}")
        
        return docs
    
    def scrape_examples(self) -> List[str]:
        """Scrape Go code examples"""
        logger.info("Scraping Go examples...")
        examples = []
        
        try:
            # Go by Example
            response = self.session.get("https://gobyexample.com/")
            response.raise_for_status()
            
            # Extract code examples (simplified)
            code_pattern = r'<pre class="code">(.*?)</pre>'
            matches = re.findall(code_pattern, response.text, re.DOTALL)
            
            for match in matches:
                # Clean HTML tags
                clean_code = re.sub(r'<[^>]+>', '', match)
                examples.append(clean_code.strip())
            
        except requests.RequestException as e:
            logger.error(f"Error scraping examples: {e}")
        
        return examples

class GoModelTrainer:
    """Main trainer class for Go AI model"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.processor = GoDataProcessor()
        self.training_data = []
    
    def collect_training_data(self, github_token: str, max_repos: int = 100):
        """Collect training data from various sources"""
        logger.info("Starting data collection...")
        
        # GitHub data
        if github_token:
            scraper = GitHubGoScraper(github_token)
            repos = scraper.get_top_go_repos(max_repos)
            
            for repo in repos[:50]:  # Limit to top 50 for now
                repo_name = repo['full_name']
                logger.info(f"Processing repository: {repo_name}")
                
                files = scraper.get_repo_files(repo_name, max_files=20)
                
                for file_info in files:
                    content = scraper.download_file_content(repo_name, file_info['path'])
                    if content:
                        cleaned_code = self.processor.clean_go_code(content)
                        if cleaned_code:
                            pairs = self.processor.create_training_pairs(
                                cleaned_code, 
                                f"from {repo_name}"
                            )
                            self.training_data.extend(pairs)
        
        # Documentation data
        docs_scraper = GoDocsScraper()
        docs = docs_scraper.scrape_documentation()
        examples = docs_scraper.scrape_examples()
        
        # Process documentation
        for page, content in docs.items():
            if content:
                pairs = self.processor.create_training_pairs(
                    content[:1000], 
                    f"Go documentation from {page}"
                )
                self.training_data.extend(pairs)
        
        # Process examples
        for example in examples:
            if example:
                pairs = self.processor.create_training_pairs(example, "Go example")
                self.training_data.extend(pairs)
        
        logger.info(f"Collected {len(self.training_data)} training pairs")
    
    def save_training_data(self, output_file: str = "training_data.json"):
        """Save training data to file"""
        logger.info(f"Saving training data to {output_file}")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.training_data, f, indent=2, ensure_ascii=False)
    
    def load_training_data(self, input_file: str = "training_data.json"):
        """Load training data from file"""
        logger.info(f"Loading training data from {input_file}")
        
        if os.path.exists(input_file):
            with open(input_file, 'r', encoding='utf-8') as f:
                self.training_data = json.load(f)
            logger.info(f"Loaded {len(self.training_data)} training pairs")
        else:
            logger.warning(f"Training data file {input_file} not found")
    
    def prepare_dataset(self):
        """Prepare dataset for training"""
        logger.info("Preparing dataset...")
        
        if not self.training_data:
            logger.error("No training data available")
            return None
        
        # Format data for training
        formatted_data = []
        for item in self.training_data:
            text = f"Human: {item['prompt']}\nAssistant: {item['completion']}<|endoftext|>"
            formatted_data.append(text)
        
        return formatted_data
    
    def train_model(self):
        """Train the model (placeholder for actual training)"""
        logger.info("Starting model training...")
        
        dataset = self.prepare_dataset()
        if not dataset:
            logger.error("Failed to prepare dataset")
            return
        
        # This is a placeholder - actual training would use transformers library
        logger.info(f"Training model with {len(dataset)} examples")
        logger.info("Model training completed (placeholder)")
        
        # Save model configuration
        config = {
            "base_model": self.config.base_model,
            "training_examples": len(dataset),
            "max_length": self.config.max_length,
            "batch_size": self.config.batch_size,
            "num_epochs": self.config.num_epochs
        }
        
        with open(f"{self.config.output_dir}/training_config.json", 'w') as f:
            json.dump(config, f, indent=2)
        
        logger.info(f"Model saved to {self.config.output_dir}")

def main():
    """Main function"""
    # Configuration
    config = TrainingConfig(
        base_model="microsoft/DialoGPT-medium",
        output_dir="./go-ai-model",
        max_length=512,
        batch_size=4,
        num_epochs=3
    )
    
    # Get GitHub token from environment
    github_token = os.getenv('GITHUB_TOKEN')
    if not github_token:
        logger.warning("GITHUB_TOKEN not set, skipping GitHub data collection")
    
    # Create trainer
    trainer = GoModelTrainer(config)
    
    # Collect training data
    trainer.collect_training_data(github_token, max_repos=50)
    
    # Save training data
    trainer.save_training_data()
    
    # Train model
    trainer.train_model()
    
    logger.info("Training pipeline completed!")

if __name__ == "__main__":
    main()
